# Report 2

## Ridge Regression

**By Yousef Tarek 202201545**<br/><br/>
**Ridge Regression** is a technique for analyzing multiple regression data that suffer from multicollinearity. When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from the true value. By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors.

## Lasso Regression

**By Mohamed Hozien 202201507**<br/>
**Lasso Regression** is a type of linear regression that uses shrinkage. Shrinkage is where data values are shrunk towards a central point, like the mean. The lasso procedure encourages simple, sparse models (i.e. models with fewer parameters). This particular type of regression is well-suited for models showing high levels of multicollinearity or when you want to automate certain parts of model selection, like variable selection/parameter elimination.

## Elastic Net Regression

**By Ziad Moataz2 202201252**<br/>
**Elastic Net Regression** is a type of linear regression that uses L1 and L2 regularization to prevent overfitting. It is a combination of L1 and L2 regularization. The L1 regularization adds a penalty equal to the absolute value of the magnitude of coefficients. The L2 regularization adds a penalty equal to the square of the magnitude of coefficients. The elastic net adds both of these penalties to the loss function.
